---
title: "EDS222 Week 8 Lab: Hypothesis testing"
format: 
  html:
    echo: true
    eval: false
    code-tools: true
bibliography: references.bib
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
theme_set(theme_classic(14))

```

# To lead poison a mockingbird

## Background

Lead is an important contaminant in urban areas with well-known impacts on human health, but do non-human animals also face risks from lead exposure? Hitt *et al.* investigated this question by measuring lead levels in soil and the blood of breeding mockingbirds, as well as egg hatching and offspring development [@hitt2023]. We will replicate parts of their analysis here.

## Get the data

The data for this study were deposited in the Dryad Data Repository and are available [here](https://datadryad.org/stash/dataset/doi:10.5061/dryad.tht76hf3v). Download the full dataset and put them in the appropriate folder of your RStudio project.

Read the northern mockingbird nestling data ("NOMO_Nest_Data.csv") and nestling lead data ("NestlingPb.csv") into data frames called `nest_data` and `nestlingpb_data`, respectively. Filter both data frames to the Uptown and Lakeshore neighborhoods.

```{r}
#| label: load-data
nest_data <- read_csv(here::here("eds222_labs", "week8-data", "NOMO_Nest_Data.csv")) %>% 
  filter(hood %in% c("ls", "up"))

nestlingpb_data <- read_csv(here::here("eds222_labs","week8-data", "NestlingPb.csv")) %>% 
  filter(hood %in% c("lakeshore", "uptown"))
```

## Hypothesis testing by randomization

*Do mockingbirds in a neighborhood with higher lead concentrations have less successful nests?*

We'll investigate this question using randomization hypothesis testing.

### Nest success

`nest_data` contains columns `hood` and `bin.status`, representing the neighborhood and *binary status* (at least one chick fledged or not) for each monitored nest. Visualize how nest success (i.e., binary status) varied by neighborhood.

```{r}
#| label: visualize-success

ggplot(data = nest_data) + 
  geom_bar(aes(hood,fill = factor(bin.status))) + 
  scale_fill_brewer("Nest Success", palette = "Dark2")


```

#### Step 1: state the null and alternative hypotheses

*H~0~: Neighborhood has no affect on nest success\
H~A~: Neighborhood has an effect on nest success*

#### Step 2: calculate the point statistic

1\) What is the relevant sample statistic for our hypothesis?

Difference in proportions

2\) How would you calculate it?

```{r}
#| label: point-estimate-success

nest_success <- nest_data %>% 
  group_by(hood) %>% 
  summarise(prop = sum(bin.status) / n())

point_estimate_success <- nest_success$prop[2] - nest_success$prop[1]

```

#### Step 3: quantify the uncertainty

Use randomization to simulate the distribution of the sample statistic under the null hypothesis.

```{r}
#| label: randomization-success

null_dist <- replicate(1000, {
  # Estimate point estimates success
  nest_success <- nest_data %>%
    # Shuffle the sample data to randomize/mix up neighborhood vector
    mutate(hood = sample(hood, n())) %>%
    group_by(hood) %>%
    summarize(prop = sum(bin.status) / n())
  # Take the proportions between the neighborhoods if we were to totally randomize it
  point_estimate_success <- nest_success$prop[2] - nest_success$prop[1]
  point_estimate_success
})
# Visualize the new proportions of randomized data for null distribution
ggplot(tibble(null_dist), aes(null_dist)) +
  geom_histogram(bins = 20,
                 color = "cornflowerblue",
                 fill = NA) +
  geom_vline(xintercept = point_estimate_success,
             color = "firebrick")
```

#### Step 4: calculate probability of the point estimate under the null

What's the p-value?

```{r}
#| label: pval-success

sum(abs(null_dist) > abs(point_estimate_success)) /
  length(null_dist)

```

#### Step 5: reject or fail to reject the null

Alpha = 0.05, p\>0.05, so we fail to reject the null.

### Nestling blood lead levels

Now it's your turn. Perform a similar analysis to investigate whether nestling blood Pb levels vary by neighborhood. Use `nestlingpb_data` for this part, column `blood_ug_dl_pbwt`.

First, visualize the blood Pb levels by neighborhood. What's an appropriate type of visualization for this?

```{r}
#| label: visualize-bloodpb

ggplot(data = nestlingpb_data, aes(x = hood, y = blood_ug_dl_pbwt)) +
  geom_violin(color = "cornflowerblue")

```

#### Step 1: state the null and alternative hypotheses

*H~0~: Neighborhood has no effect on blood Pb levels in mockingbird nestilings\
H~A~: Neighborhood has an effect on blood Pb levels in mockingbird nestilings*

#### Step 2: calculate the point statistic

1\) What is the relevant sample statistic for our hypothesis?

Difference in mean between the neighborhoods

2\) How would you calculate it?

```{r}
#| label: point-estimate-bloodpb

diff_mean <- nestlingpb_data %>% 
  group_by(hood) %>% 
  summarise(mean = mean(blood_ug_dl_pbwt)) 
  
difference <- diff_mean$mean[2] - diff_mean$mean[1]
  

```

#### Step 3: quantify the uncertainty

Use randomization to simulate the distribution of the sample statistic under the null hypothesis.

```{r}
#| label: randomization-bloodpb

null_diff <- replicate(1000, {
  diff_mean <- nestlingpb_data %>% 
  mutate(hood = sample(hood, n())) %>% 
  group_by(hood) %>% 
  summarise(mean = mean(blood_ug_dl_pbwt)) 
  
difference <- diff_mean$mean[2] - diff_mean$mean[1]
})


ggplot(tibble(null_diff), aes(null_diff)) +
  geom_histogram(bins = 20,
                 color = "cornflowerblue",
                 fill = NA) +
  geom_vline(xintercept = difference,
             color = "firebrick")
```

#### Step 4: calculate probability of the point estimate under the null

What's the p-value?

```{r}
#| label: pval-bloodpb



```

#### Step 5: reject or fail to reject the null

## Hypothesis testing by normal approximation

Rather than using randomization to simulate the null distribution, it's often easier to approximate it as a normal distribution.

***Does nestling blood Pb level have a relationship with feather Pb level?***

First, visualize the relationship between the two variables.

```{r}
#| label: blood-feathers-visualization

ggplot(nestlingpb_data, aes(blood_ug_dl_pbwt, feather_ug_g_pbwt)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, linewidth = 1.5)

```

#### Step 1: state the null and alternative hypotheses

*H~0~:\
H~A~:*

#### Step 2: calculate the point statistic

1\) What is the relevant sample statistic for our hypothesis?

Regression coefficient

2\) How would you calculate it?

```{r}
#| label: blood-feathers-lm
blood_feathers_lm <- lm(feather_ug_g_pbwt~blood_ug_dl_pbwt, data = nestlingpb_data)

```

#### Step 3: quantify the uncertainty

Use the standard error of the regression coefficient to visualize the distribution of the sample statistic under the null hypothesis.

```{r}
#| label: blood-feathers-null

beta1_estimate <- summary(blood_feathers_lm)$coefficients[2, 1]
beta1_se <- summary(blood_feathers_lm)$coefficients[2, 2]

tibble(beta1 = seq(-(beta1_estimate + beta1_se),
                   beta1_estimate + beta1_se,
                   length.out = 200),
       density = dnorm(beta1, mean = 0, sd = beta1_se)) %>% 
  ggplot(aes(beta1, density)) +
  geom_line(color = "blue") +
  geom_vline(xintercept = beta1_estimate, color = "red")
```

#### Step 4: calculate probability of the point estimate under the null

What's the p-value? Use `pnorm()` to get the probability of a point estimate at least as extreme as the observed.

```{r}
#| label: blood-feathers-pval
pval <- 2 * pnorm(-abs(beta1_estimate), mean = 0, sd = beta1_se)
pval

```

::: callout-note
Our calculate p-value is much lower than the p-value from the summary of our linear model. In class I told you `lm()` uses a *Student's t-distribution* instead of a normal distribution for calculating the p-value. When sample sizes are large, the normal distribution and t-distribution are virtually identical. With only 22 complete data points, our sample size is relatively small. Therefore the t-distribution has *thicker tails* and yields a larger p-value. Hence the discrepancy.
:::

#### Step 5: reject or fail to reject the null

### Sensitivity to outliers

Revisit the visualization of the blood and feather Pb levels. One point seems to be an extreme outlier, and it seems to be exerting a strong influence on our model. Repeat the previous analysis with that point removed, then answer the question below.

```{r}
#| label: remove-outlier
# Remove outlier 
no_outlier <- nestlingpb_data %>% 
  filter(blood_ug_dl_pbwt < 40)
```


Step 1 state your hypothesis 

*H~0~:\ Blood lead levels do not impact feather Pb level 
H~A~:* Blood levels do impact feather Pb levels 


```{r}
# Step 2 calculate your point estimate
blood_feathers_lm2 <- lm(feather_ug_g_pbwt~blood_ug_dl_pbwt, data = no_outlier)

```


Step 3 quanify the uncertainity (estimate +- SE)
```{r}
beta1_estimate <- summary(blood_feathers_lm2)$coefficients[2, 1]
beta1_se <- summary(blood_feathers_lm2)$coefficients[2, 2]

tibble(beta1 = seq(-(beta1_estimate + beta1_se),
                   beta1_estimate + beta1_se,
                   length.out = 200),
       density = dnorm(beta1, mean = 0, sd = beta1_se)) %>% 
  ggplot(aes(beta1, density)) +
  geom_line(color = "blue") +
  geom_vline(xintercept = beta1_estimate, color = "red")
```


Step 4 calculate your p-value 
```{r}
pval <- 2 * pnorm(-abs(beta1_estimate), mean = 0, sd = beta1_se)
pval
```


# Step 5 interpret 

Higher p-value than with the outlier, but still significant


**Question:** Of the two analyses (with and without the outlier), which had a lower p-value? Does that make it a better analysis?

## Confidence intervals

For the last part of today's lab we will construct confidence intervals around the point estimate of the blood Pb level coefficient. Here's the plan:

1.  Simulate a population of nestlings, with the same relationship between blood and feather Pb levels as the observed sample.

2.  Draw a new sample of nestlings from the simulated population. Create a confidence interval for the point estimate of the blood Pb level coefficient in this sample.

3.  Repeat the process 100 times.

\~95% of our 95% CIs should contain the population parameter.

### 1. Simulate the population

```{r}
#| label: blood-feather-pop
# Simulate 

beta0_estimate <- summary(blood_feathers_lm2)$coefficients[1, 1]
beta1_estimate <- summary(blood_feathers_lm2)$coefficients[2, 1]
sigma_estimate <- summary(blood_feathers_lm2)$sigma

blood_feather_pop <- tibble(
  #predictor
  blood_ug_dl_pbwt = runif(1e4,
                           min(no_outlier$blood_ug_dl_pbwt),
                           max(no_outlier$blood_ug_dl_pbwt)),
  # Mean response 
  mean_feather = beta0_estimate + beta1_estimate * blood_ug_dl_pbwt,
  # Simulated response 
  feather_ug_g_pbwt = rnorm(1e4, mean = mean_feather, sd = sigma_estimate)
)


# Visualize 
ggplot(blood_feather_pop, aes(blood_ug_dl_pbwt, feather_ug_g_pbwt)) +
  geom_point(shape = 21)

# verify coefs match  
c(beta0_estimate, beta1_estimate)
summary(lm(feather_ug_g_pbwt~blood_ug_dl_pbwt,
           blood_feather_pop))
```


Notice there are negative numbers (not possible), but for now we are going to be ok with it for the example 

### 2. Create one confidence interval

```{r}
#| label: blood-feather-ci

# draw a sample 
blood_feather_sample <- sample_n(blood_feather_pop, 21) #picks rows from a data frame 

# Calculate the point estimate and standard error from the sample 
sample_lm <- lm(feather_ug_g_pbwt~blood_ug_dl_pbwt,
           blood_feather_sample)

point_est <- summary(sample_lm)$coefficients[2, 1]
sample_error <- summary(sample_lm)$coefficients[2, 2]
c(point_est, sample_error)

# Confidence interval 
sample_ci <- c(point_estimate = point_est, 
               ci95_lower = point_est - 1.96 * sample_error,
               ci95_upper = point_est + 1.96 * sample_error)
sample_ci
```

### 3. Repeat the process

How many 95% CIs contain the population parameter?

```{r}
#| label: repeat-ci

repeat_ci <- replicate(100, {
  
  # draw a sample 
  blood_feather_sample <- sample_n(blood_feather_pop, 21) #picks rows from a data frame 
  
  # Calculate the point estimate and standard error from the sample 
  sample_lm <- lm(feather_ug_g_pbwt~blood_ug_dl_pbwt,
                  blood_feather_sample)
  
  point_est <- summary(sample_lm)$coefficients[2, 1]
  sample_error <- summary(sample_lm)$coefficients[2, 2]
  c(point_est, sample_error)
  
  # Confidence interval 
  sample_ci <- c(point_estimate = point_est, 
                 ci95_lower = point_est - 1.96 * sample_error,
                 ci95_upper = point_est + 1.96 * sample_error)
  sample_ci
})

tibble(point_estimate = repeat_ci[1, ],
       ci95_lower = repeat_ci[2, ],
       ci95_upper = repeat_ci[3, ],
       ci = 1:100) %>% 
  mutate(valid = beta1_estimate >= ci95_lower &
           beta1_estimate <= ci95_upper) %>% 
  ggplot() +
  geom_pointrange(aes(x = point_estimate, 
                      xmin = ci95_lower, 
                      xmax = ci95_upper, 
                      y = ci,
                      color = valid)) +
  geom_vline(xintercept = beta1_estimate, color = "red")

```

## Recap

-   Randomization allows us to simulate the null distribution, which we can use to quantify the probability of our result if the null hypothesis is true.

    -   `sample()` and `replicate()` are helpful here!

    -   Randomization doesn't make assumptions about the normality of the sample statistic, but it does assume the sample is representative of the population.

-   By assuming the sample statistic is normally distributed, we can use standard errors to conduct hypothesis testing.

    -   R will calculate standard errors for us for most sample statistics, such as regression coefficients.

-   We can also use standard errors to construct confidence intervals.

    -   By simulating a population, we demonstrated \~95% of 95% CIs will contain the population parameter.
